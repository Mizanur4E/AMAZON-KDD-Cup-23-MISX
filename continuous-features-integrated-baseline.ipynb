{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nimport pandas as pd\n\n#corresponding to model\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Embedding, GRU, Dense, Concatenate, Dropout, Reshape\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2023-06-07T11:19:13.072422Z","iopub.execute_input":"2023-06-07T11:19:13.072997Z","iopub.status.idle":"2023-06-07T11:19:21.743064Z","shell.execute_reply.started":"2023-06-07T11:19:13.072959Z","shell.execute_reply":"2023-06-07T11:19:21.742063Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":" class Metesre():\n        \n        def __init__(self):\n            \n            \n            item_ids = pd.read_parquet('/kaggle/input/etl-de-nopadding/categories_DE_full_new/kaggle/working/categories/unique.prev_items.parquet')\n            self.items = item_ids['prev_items']\n            self.sessions_gdf = pd.read_parquet(\"/kaggle/input/etl-de-nopadding/processed_DE_full_new/kaggle/working/processed_nvt/part_0.parquet\")\n            self.test_gdf = pd.read_parquet(\"/kaggle/input/etl-de-nopadding/processed_DE_full_new/kaggle/working/processed_nvt/test_0.parquet\")\n            self.preprocessing()\n            self.buildModel()\n            \n            \n        def preprocessing(self):\n            \n            \n            X1 = self.sessions_gdf['prev_items-list'].tolist()\n            X2 = self.sessions_gdf['title-list'].tolist()\n            X3 = self.sessions_gdf['brand-list'].tolist()\n            X4 = self.sessions_gdf['size-list'].tolist()\n            X5 = self.sessions_gdf['model-list'].tolist()\n            X6 = self.sessions_gdf['color-list'].tolist()\n            X7 = self.sessions_gdf['price_log_norm-list'].tolist()\n            X8 = self.sessions_gdf['relative_price_to_avg_categ_id-list'].tolist()\n            \n            #handles variable length session sequences\n            X1 = np.array(X1, dtype='object')\n\n            #find vocab sizes\n            self.vocab_size1 = max(item for sublist in X1 for item in sublist)+1\n            self.vocab_size2 = max(item for sublist in X2 for item in sublist)+1\n            self.vocab_size3 = max(item for sublist in X3 for item in sublist)+1\n            self.vocab_size4 = max(item for sublist in X4 for item in sublist)+1\n            self.vocab_size5 = max(item for sublist in X5 for item in sublist)+1\n            self.vocab_size6 = max(item for sublist in X6 for item in sublist)+1\n            \n            print(\"Vocab Sizes: \\n\",self.vocab_size1, self.vocab_size2, self.vocab_size3, self.vocab_size4, self.vocab_size5, self.vocab_size6)\n            \n            #extract next item from the X1: prev_items_list, also remove last items attributes\n            X1_p = []\n            X2_p = []\n            X3_p = []\n            X4_p = []\n            X5_p = []\n            X6_p = []\n            X7_p = []\n            X8_p = []\n\n            y_p = []\n\n            for i in range(len(X1)):\n                X1_p.append(X1[i][:-1])\n                X2_p.append(X2[i][:-1])\n                X3_p.append(X3[i][:-1])\n                X4_p.append(X4[i][:-1])\n                X5_p.append(X5[i][:-1])\n                X6_p.append(X6[i][:-1])\n                X7_p.append(X5[i][:-1])\n                X8_p.append(X6[i][:-1])\n                y_p.append(X1[i][-1])\n                \n        \n            X1 = X1_p\n            X2 = X2_p\n            X3 = X3_p\n            X4 = X4_p\n            X5 = X5_p\n            X6 = X6_p\n            X7 = X7_p\n            X8 = X8_p\n            y= y_p\n            y = np.array(y)\n            self.max_len = 10\n            #padding: pre for X1 and post for all others\n            X1 = pad_sequences(X1, maxlen=self.max_len, padding='pre')\n            X2 = pad_sequences(X2, maxlen=self.max_len, padding='pre')\n            X3 = pad_sequences(X3, maxlen=self.max_len, padding='pre')\n            X4 = pad_sequences(X4, maxlen=self.max_len, padding='pre')\n            X5 = pad_sequences(X5, maxlen=self.max_len, padding='pre')\n            X6 = pad_sequences(X6, maxlen=self.max_len, padding='pre')\n            X7 = pad_sequences(X7, maxlen=self.max_len, padding='pre')\n            X8 = pad_sequences(X8, maxlen=self.max_len, padding='pre')\n\n            self.X1_train, self.X1_test, self.X2_train, self.X2_test, self.X3_train, self.X3_test, self.X4_train, \\\n            self.X4_test , self.X5_train, self.X5_test, self.X6_train, self.X6_test, self.X7_train, self.X7_test, self.X8_train, self.X8_test,  self.y_train, self.y_test = train_test_split(X1, X2, X3, X4, \\\n                                                                                              X5, X6, X7, X8, y, test_size=0.005,random_state=42, shuffle=True)\n        \n        def buildModel(self):\n            \n            \n            embedding_dim = 128\n            hidden_units = 512\n            seq_length = self.max_len\n\n            # Define the input layers\n            input_layer1 = tf.keras.Input(shape=(seq_length,))\n            input_layer2 = tf.keras.Input(shape=(seq_length,))\n            input_layer3 = tf.keras.Input(shape=(seq_length,))\n            input_layer4 = tf.keras.Input(shape=(seq_length,))\n            input_layer5 = tf.keras.Input(shape=(seq_length,))\n            input_layer6 = tf.keras.Input(shape=(seq_length,))\n            input_layer7 = tf.keras.Input(shape=(seq_length,))\n            input_layer8 = tf.keras.Input(shape=(seq_length,))\n\n            \n            # Define the embedding layers\n            embedding_layer1 = Embedding(self.vocab_size1, embedding_dim)\n            embedding_layer2 = Embedding(self.vocab_size2, embedding_dim)\n            embedding_layer3 = Embedding(self.vocab_size3, embedding_dim)\n            embedding_layer4 = Embedding(self.vocab_size4, embedding_dim)\n            embedding_layer5 = Embedding(self.vocab_size5, embedding_dim)\n            embedding_layer6 = Embedding(self.vocab_size6, embedding_dim)\n            \n\n            gru_layer = GRU(hidden_units, return_sequences=False)\n            \n            # Define the dropout layer\n            dropout_layer = Dropout(0.3)\n\n            # Define the output layer\n            output_layer = Dense(self.vocab_size1, activation='softmax')\n\n            # Connect the layers\n            embedded_input1 = embedding_layer1(input_layer1)\n            embedded_input2 = embedding_layer2(input_layer2)\n            embedded_input3 = embedding_layer3(input_layer3)\n            embedded_input4 = embedding_layer4(input_layer4)\n            embedded_input5 = embedding_layer5(input_layer5)\n            embedded_input6 = embedding_layer6(input_layer6)\n            \n\n\n            input7_cont = Reshape(target_shape=(seq_length, 1))(input_layer7)\n            input8_cont = Reshape(target_shape=(seq_length, 1))(input_layer8)\n\n            emb_cont1 = Dense(embedding_dim)(input7_cont)\n            emb_cont2 = Dense(embedding_dim)(input8_cont)\n\n            # Concatenate the outputs of the two GRU layers\n            concatenated_output = Concatenate()([embedded_input1, embedded_input2, embedded_input3, embedded_input4, embedded_input5, embedded_input6, emb_cont1, emb_cont2])\n\n            gru_output = gru_layer(concatenated_output)\n\n\n            output = output_layer(gru_output)\n\n\n            # Create the model\n            self.model = Model(inputs=[input_layer1, input_layer2, input_layer3, input_layer4, input_layer5, input_layer6, input_layer7, input_layer8], outputs=output)\n\n            # Compile the model\n            self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.CosineSimilarity(axis=1)])\n\n            # Print the model summary\n            self.model.summary()\n\n\n            \n        def _mean_reciprocal_rank(self, recommendations, ground_truth):\n            \"\"\"\n            Calculate the Mean Reciprocal Rank (MRR) of a recommendation system.\n\n            :param recommendations: A list of lists containing the recommended items for each query.\n            :param ground_truth: A list containing the ground truth (relevant) items for each query.\n            :return: The Mean Reciprocal Rank (MRR) value as a float.\n            \"\"\"\n            assert len(recommendations) == len(ground_truth), \"Recommendations and ground truth lists must have the same length.\"\n\n            reciprocal_ranks = []\n\n            for rec, gt in zip(recommendations, ground_truth):\n                for rank, item in enumerate(rec, start=1):\n                    if item == gt:\n                        reciprocal_ranks.append(1 / rank)\n                        break\n                else:\n                    reciprocal_ranks.append(0)\n\n            mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n            return mrr\n\n\n        def train(self, epoch= 10, batch_size = 32):\n            \n            checkpoint_callback = ModelCheckpoint(\n                '/kaggle/working/model_checkpoint.h5',\n                monitor='val_cosine_similarity',  \n                save_best_only=True,  \n                save_weights_only=False, \n                verbose=1 \n            )\n            \n            self.history = self.model.fit([ self.X1_train, self.X2_train, self.X3_train, self.X4_train, self.X5_train, self.X6_train, self.X7_train, self.X8_train], self.y_train, epochs = epoch, batch_size=batch_size, verbose = True, validation_split=0.1, callbacks=[checkpoint_callback])\n            \n        \n        \n        \n        def _decoder(self, recommendation):\n            \n            '''decode sequeces to ASIN ids'''\n            \n            decoded = []\n            for next_item in recommendation:\n\n                decoded.append([self.items.iloc[e-1] for e in next_item])\n\n            decoded = np.array(decoded)\n            return decoded\n            \n            \n            \n        def _predictor(self, X_test):\n            \n            '''generate y_pred (which is top 100 product indices) from the model for X_test. '''\n            \n            batch_size = 64\n            num_batches = int(len(X_test[0]) / batch_size)\n\n            y_pred = []\n            for batch_idx in range(num_batches+1):\n                \n                if batch_idx < num_batches:\n                    start_idx = batch_idx * batch_size\n                    end_idx = (batch_idx + 1) * batch_size\n                    \n                    inputs = []\n                \n                    for i in range(len(X_test)):\n                        inputs.append(X_test[i][start_idx:end_idx])\n                        \n                    predictions = self.model.predict(inputs)\n                    recom_size = 100\n            \n            \n                    top_preds = np.argpartition(predictions, -recom_size, axis=1)[:, -recom_size:]\n                    sorted_indices = np.argsort(predictions[np.arange(len(predictions))[:, None], top_preds], axis=1)[:, ::-1]\n                    recom = top_preds[np.arange(len(predictions))[:, None], sorted_indices]\n\n                    y_pred.append(recom)\n\n                        \n                else:\n                    \n                    inputs = []\n                \n                    for i in range(len(X_test)):\n                        \n                        inputs.append(X_test[i][end_idx:])\n                    \n                    predictions = self.model.predict(inputs)\n            \n                    top_preds = np.argpartition(predictions, -recom_size, axis=1)[:, -recom_size:]\n                    sorted_indices = np.argsort(predictions[np.arange(len(predictions))[:, None], top_preds], axis=1)[:, ::-1]\n                    recom = top_preds[np.arange(len(predictions))[:, None], sorted_indices]\n\n                    y_pred.append(recom)\n                \n            y_pred = [inner_list for outer_list in y_pred for inner_list in outer_list]\n                    \n            return y_pred\n            \n            \n        def test_1_testontest(self):\n            \n            \n            '''evaluate model's performance on the test set defined in the initialization '''\n            #update it for all the test sessions instead of only 200\n            \n            recommendation = self._predictor([self.X1_test, self.X2_test, self.X3_test, self.X4_test, self.X5_test, self.X6_test, self.X7_test, self.X8_test])\n            gnd = self.y_test.tolist()\n            self.test1_MRR = self._mean_reciprocal_rank(recommendation, gnd)\n            print(f'MRR for test1: {self.test1_MRR}')\n\n    \n        \n            \n        def test_2_testwithendone(self, n=100):\n            \n            ''' evaluate model's performance on the given test set. Since test set has no ground truth\n            we will split the last item in the session and consider it as the next item and evaulate model\n            performance'''\n            \n            \n            X1 = self.test_gdf['prev_items-list'].tolist()\n            X2 = self.test_gdf['title-list'].tolist()\n            X3 = self.test_gdf['brand-list'].tolist()\n            X4 = self.test_gdf['size-list'].tolist()\n            X5 = self.test_gdf['model-list'].tolist()\n            X6 = self.test_gdf['color-list'].tolist()\n            \n            #handles variable length session sequences\n            X1 = np.array(X1, dtype='object')\n\n\n            #extract next item from the X1: prev_items_list, also remove last items attributes\n            X1_p = []\n            X2_p = []\n            X3_p = []\n            X4_p = []\n            X5_p = []\n            X6_p = []\n\n            y_p = []\n\n            for i in range(len(X1)):\n                X1_p.append(X1[i][:-1])\n                X2_p.append(X2[i][:-1])\n                X3_p.append(X3[i][:-1])\n                X4_p.append(X4[i][:-1])\n                X5_p.append(X5[i][:-1])\n                X6_p.append(X6[i][:-1])\n                y_p.append(X1[i][-1])\n                \n        \n            X1 = X1_p\n            X2 = X2_p\n            X3 = X3_p\n            X4 = X4_p\n            X5 = X5_p\n            X6 = X6_p\n            y= y_p\n            y = np.array(y)\n            \n            #padding: pre for X1 and post for all others\n            X1 = pad_sequences(X1, maxlen=self.max_len, padding='pre')\n            X2 = pad_sequences(X2, maxlen=self.max_len, padding='pre')\n            X3 = pad_sequences(X3, maxlen=self.max_len, padding='pre')\n            X4 = pad_sequences(X4, maxlen=self.max_len, padding='pre')\n            X5 = pad_sequences(X5, maxlen=self.max_len, padding='pre')\n            X6 = pad_sequences(X6, maxlen=self.max_len, padding='pre')\n            \n           \n            rec = self._predictor([X1[:n], X2[:n], X3[:n], X4[:n], X5[:n], X6[:n]])\n            gnd = y[:n].tolist()\n            self.test2_MRR =  self._mean_reciprocal_rank(rec, gnd)\n            print(f'MRR for test1: {self.test2_MRR}')\n\n            \n        \n    \n        def test_3_generatefinalresult(self, n=100):\n            \n            \n            ''' generates predictions of test set. Decodes the index and return the recommendations with ASIN ids'''\n            \n            X1 = self.test_gdf['prev_items-list'].tolist()\n            X2 = self.test_gdf['title-list'].tolist()\n            X3 = self.test_gdf['brand-list'].tolist()\n            X4 = self.test_gdf['size-list'].tolist()\n            X5 = self.test_gdf['model-list'].tolist()\n            X6 = self.test_gdf['color-list'].tolist()\n            X7 = self.test_gdf['price_log_norm-list'].tolist()\n            X8 = self.test_gdf['relative_price_to_avg_categ_id-list'].tolist()\n\n            \n            X1 = pad_sequences(X1, maxlen=self.max_len, padding='pre')\n            X2 = pad_sequences(X2, maxlen=self.max_len, padding='pre')\n            X3 = pad_sequences(X3, maxlen=self.max_len, padding='pre')\n            X4 = pad_sequences(X4, maxlen=self.max_len, padding='pre')\n            X5 = pad_sequences(X5, maxlen=self.max_len, padding='pre')\n            X6 = pad_sequences(X6, maxlen=self.max_len, padding='pre')\n            X7 = pad_sequences(X7, maxlen=self.max_len, padding='pre')\n            X8 = pad_sequences(X8, maxlen=self.max_len, padding='pre')\n            \n          \n            rec = self._predictor([X1[:n], X2[:n], X3[:n], X4[:n], X5[:n], X6[:n],  X7[:n], X8[:n]])\n\n            y_pred = self._decoder(rec)\n            y_pred = y_pred.tolist()\n            df = pd.DataFrame()\n            df['next_item_prediction'] = y_pred\n            \n            return df","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-07T11:19:21.748562Z","iopub.execute_input":"2023-06-07T11:19:21.749343Z","iopub.status.idle":"2023-06-07T11:19:21.841615Z","shell.execute_reply.started":"2023-06-07T11:19:21.749305Z","shell.execute_reply":"2023-06-07T11:19:21.840729Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ob = Metesre()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T11:19:21.845893Z","iopub.execute_input":"2023-06-07T11:19:21.848260Z","iopub.status.idle":"2023-06-07T11:20:37.895877Z","shell.execute_reply.started":"2023-06-07T11:19:21.848226Z","shell.execute_reply":"2023-06-07T11:20:37.895072Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Vocab Sizes: \n 517474 494820 72004 85967 207012 81567\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_7 (InputLayer)           [(None, 10)]         0           []                               \n                                                                                                  \n input_8 (InputLayer)           [(None, 10)]         0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None, 10)]         0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, 10)]         0           []                               \n                                                                                                  \n input_3 (InputLayer)           [(None, 10)]         0           []                               \n                                                                                                  \n input_4 (InputLayer)           [(None, 10)]         0           []                               \n                                                                                                  \n input_5 (InputLayer)           [(None, 10)]         0           []                               \n                                                                                                  \n input_6 (InputLayer)           [(None, 10)]         0           []                               \n                                                                                                  \n reshape (Reshape)              (None, 10, 1)        0           ['input_7[0][0]']                \n                                                                                                  \n reshape_1 (Reshape)            (None, 10, 1)        0           ['input_8[0][0]']                \n                                                                                                  \n embedding (Embedding)          (None, 10, 128)      66236672    ['input_1[0][0]']                \n                                                                                                  \n embedding_1 (Embedding)        (None, 10, 128)      63336960    ['input_2[0][0]']                \n                                                                                                  \n embedding_2 (Embedding)        (None, 10, 128)      9216512     ['input_3[0][0]']                \n                                                                                                  \n embedding_3 (Embedding)        (None, 10, 128)      11003776    ['input_4[0][0]']                \n                                                                                                  \n embedding_4 (Embedding)        (None, 10, 128)      26497536    ['input_5[0][0]']                \n                                                                                                  \n embedding_5 (Embedding)        (None, 10, 128)      10440576    ['input_6[0][0]']                \n                                                                                                  \n dense_1 (Dense)                (None, 10, 128)      256         ['reshape[0][0]']                \n                                                                                                  \n dense_2 (Dense)                (None, 10, 128)      256         ['reshape_1[0][0]']              \n                                                                                                  \n concatenate (Concatenate)      (None, 10, 1024)     0           ['embedding[0][0]',              \n                                                                  'embedding_1[0][0]',            \n                                                                  'embedding_2[0][0]',            \n                                                                  'embedding_3[0][0]',            \n                                                                  'embedding_4[0][0]',            \n                                                                  'embedding_5[0][0]',            \n                                                                  'dense_1[0][0]',                \n                                                                  'dense_2[0][0]']                \n                                                                                                  \n gru (GRU)                      (None, 512)          2362368     ['concatenate[0][0]']            \n                                                                                                  \n dense (Dense)                  (None, 517474)       265464162   ['gru[0][0]']                    \n                                                                                                  \n==================================================================================================\nTotal params: 454,559,074\nTrainable params: 454,559,074\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"recommendation = ob._predictor([ob.X1_test[:3000], ob.X2_test[:3000], ob.X3_test[:3000], ob.X4_test[:3000], ob.X5_test[:3000], ob.X6_test[:3000], ob.X7_test[:3000], ob.X8_test[:3000]])\ngnd = ob.y_test[:3000].tolist()\ntest1_MRR = ob._mean_reciprocal_rank(recommendation, gnd)\nprint(f'MRR for test1: {test1_MRR}')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T11:20:37.897837Z","iopub.execute_input":"2023-06-07T11:20:37.898192Z","iopub.status.idle":"2023-06-07T11:21:11.963561Z","shell.execute_reply.started":"2023-06-07T11:20:37.898158Z","shell.execute_reply":"2023-06-07T11:21:11.962484Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"2/2 [==============================] - 2s 6ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 12ms/step\n2/2 [==============================] - 0s 7ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 9ms/step\nMRR for test1: 7.63888888888889e-06\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(6):\n    \n    ob.train(epoch=1)\n    n = 1+i\n    recommendation = ob._predictor([ob.X1_test[:3000], ob.X2_test[:3000], ob.X3_test[:3000], ob.X4_test[:3000], ob.X5_test[:3000], ob.X6_test[:3000], ob.X7_test[:3000], ob.X8_test[:3000]])\n    gnd = ob.y_test[:3000].tolist()\n    test1_MRR = ob._mean_reciprocal_rank(recommendation, gnd)\n    print(f'MRR for test1: {test1_MRR}')\n    \n    recommendation = ob._predictor([ob.X1_train[:3000], ob.X2_train[:3000], ob.X3_train[:3000], ob.X4_train[:3000], ob.X5_train[:3000], ob.X6_train[:3000], ob.X7_train[:3000], ob.X8_train[:3000]])\n    gnd = ob.y_train[:3000].tolist()\n    train_MRR = ob._mean_reciprocal_rank(recommendation, gnd)\n    print(f'MRR for trainset: {train_MRR}')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T11:21:11.965356Z","iopub.execute_input":"2023-06-07T11:21:11.966053Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":" 9285/34029 [=======>......................] - ETA: 28:06 - loss: 13.7475 - cosine_similarity: 140.5968","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}